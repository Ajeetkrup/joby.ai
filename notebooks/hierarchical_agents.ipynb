{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXNXS8iGPMfz"
      },
      "source": [
        "# Hierarchical Agent System with LangGraph\n",
        "\n",
        "This notebook demonstrates a hierarchical agent system where a **Router Agent** analyzes user input (containing job requirements and a task) and routes it to either a **Resume Maker** or a **Cover Letter Writer**."
      ],
      "id": "cXNXS8iGPMfz"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWIJOMAZPMf1",
        "outputId": "3368d025-d829-4fcd-e7ff-8590c97a71f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.80)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.36.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.43)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Downloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-1.1.0-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-1.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.36.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, groq, langchain-core, langgraph-checkpoint, langchain-groq, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "Successfully installed groq-0.36.0 langchain-1.1.0 langchain-core-1.1.0 langchain-groq-1.1.0 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.9 ormsgpack-1.12.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langgraph langchain langchain-groq"
      ],
      "id": "CWIJOMAZPMf1"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "sT-Vow3UPMf3",
        "outputId": "ddc4cbba-519b-4b9f-abd5-1121affe9dcb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1757920500.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"GROQ_API_KEY\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GROQ_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your Groq API Key: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")"
      ],
      "id": "sT-Vow3UPMf3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHJMcnPtPMf4"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Literal\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# 1. Define State\n",
        "class AgentState(TypedDict):\n",
        "    messages: list\n",
        "    next_step: Literal[\"resume_check\", \"resume_maker\", \"cover_letter_writer\", \"FINISH\"]\n",
        "    user_input: str\n",
        "    final_output: str"
      ],
      "id": "qHJMcnPtPMf4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7dnuzjFPMf4"
      },
      "outputs": [],
      "source": [
        "# Setup LLM\n",
        "llm = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0.7)"
      ],
      "id": "Y7dnuzjFPMf4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY8MsEcgPMf5"
      },
      "outputs": [],
      "source": [
        "# 2. Define Router Agent\n",
        "def router_node(state: AgentState):\n",
        "    print(\"--- ROUTER AGENT ---\")\n",
        "    user_input = state[\"user_input\"]\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a helpful router agent. Your job is to analyze the user's input, \"\n",
        "        \"which contains job requirements and a specific task request. \"\n",
        "        \"Determine if the user wants a 'Resume' or a 'Cover Letter'. \"\n",
        "        \"Return ONLY the word 'resume' or 'cover_letter'.\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=system_prompt),\n",
        "        HumanMessage(content=user_input)\n",
        "    ]\n",
        "\n",
        "    response = llm.invoke(messages)\n",
        "    decision = response.content.strip().lower()\n",
        "\n",
        "    if \"resume\" in decision:\n",
        "        return {\"next_step\": \"resume_check\"} # Route to check first\n",
        "    elif \"cover\" in decision:\n",
        "        return {\"next_step\": \"cover_letter_writer\"}\n",
        "    else:\n",
        "        return {\"next_step\": \"FINISH\", \"final_output\": \"Could not determine intent.\"}"
      ],
      "id": "jY8MsEcgPMf5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stt8bgB0PMf5"
      },
      "outputs": [],
      "source": [
        "# 3. Define Specialized Agents\n",
        "\n",
        "def resume_check_node(state: AgentState):\n",
        "    print(\"--- RESUME CHECK AGENT ---\")\n",
        "    user_input = state[\"user_input\"]\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a Resume Quality Checker. Analyze the following user input. \"\n",
        "        \"Check if it contains sufficient information for: 1. Contact Info, 2. Skills, 3. Experience, 4. Education. \"\n",
        "        \"If ANY of these are missing, list what is missing and ask the user to provide it. \"\n",
        "        \"If ALL are present, return ONLY the word 'PROCEED'.\\n\\n\"\n",
        "        f\"Input: {user_input}\"\n",
        "    )\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    content = response.content.strip()\n",
        "\n",
        "    if \"PROCEED\" in content.upper():\n",
        "        return {\"next_step\": \"resume_maker\"}\n",
        "    else:\n",
        "        return {\"final_output\": content, \"next_step\": \"FINISH\"}\n",
        "\n",
        "def resume_maker_node(state: AgentState):\n",
        "    print(\"--- RESUME MAKER AGENT ---\")\n",
        "    user_input = state[\"user_input\"]\n",
        "\n",
        "    prompt = (\n",
        "        \"You are an expert Resume Writer. \"\n",
        "        \"Based on the following job requirements and user details, create a professional resume. \"\n",
        "        \"Do not add anything if user has not given, if any section is missing ask from user and then only create the resume.\\n\\n\"\n",
        "        f\"Input: {user_input}\"\n",
        "    )\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    return {\"final_output\": response.content, \"next_step\": \"FINISH\"}\n",
        "\n",
        "def cover_letter_writer_node(state: AgentState):\n",
        "    print(\"--- COVER LETTER WRITER AGENT ---\")\n",
        "    user_input = state[\"user_input\"]\n",
        "\n",
        "    prompt = (\n",
        "        \"You are an expert Cover Letter Writer. \"\n",
        "        \"Based on the following job requirements and user details, write a compelling cover letter. \"\n",
        "        \"Do not make things on your own, cover letter should be as per the user details.\\n\\n\"\n",
        "        f\"Input: {user_input}\"\n",
        "    )\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    return {\"final_output\": response.content, \"next_step\": \"FINISH\"}"
      ],
      "id": "Stt8bgB0PMf5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yDZegthPMf5"
      },
      "outputs": [],
      "source": [
        "# 4. Build Graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"router\", router_node)\n",
        "workflow.add_node(\"resume_check\", resume_check_node)\n",
        "workflow.add_node(\"resume_maker\", resume_maker_node)\n",
        "workflow.add_node(\"cover_letter_writer\", cover_letter_writer_node)\n",
        "\n",
        "workflow.set_entry_point(\"router\")\n",
        "\n",
        "def route_decision(state: AgentState):\n",
        "    return state[\"next_step\"]\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    route_decision,\n",
        "    {\n",
        "        \"resume_check\": \"resume_check\",\n",
        "        \"cover_letter_writer\": \"cover_letter_writer\",\n",
        "        \"FINISH\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"resume_check\",\n",
        "    route_decision,\n",
        "    {\n",
        "        \"resume_maker\": \"resume_maker\",\n",
        "        \"FINISH\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"resume_maker\", END)\n",
        "workflow.add_edge(\"cover_letter_writer\", END)\n",
        "\n",
        "app = workflow.compile()"
      ],
      "id": "-yDZegthPMf5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr8-6rNRPMf6"
      },
      "outputs": [],
      "source": [
        "# 5. Execute Graph\n",
        "\n",
        "def run_agent(user_input):\n",
        "    initial_state = {\"user_input\": user_input, \"messages\": []}\n",
        "    result = app.invoke(initial_state)\n",
        "    return result.get(\"final_output\")"
      ],
      "id": "Gr8-6rNRPMf6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gexNAAFdPMf6"
      },
      "outputs": [],
      "source": [
        "# Example 1: Incomplete Resume Request\n",
        "input_1 = \"\"\"\n",
        "I need a resume for a Senior Python Developer role.\n",
        "Requirements: 5+ years of Python, Django, FastAPI, AWS experience.\n",
        "My details: Ajeet, 6 years exp in Python.\n",
        "\"\"\"\n",
        "print(\"--- Test 1: Incomplete Input ---\")\n",
        "print(run_agent(input_1))"
      ],
      "id": "gexNAAFdPMf6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRDoR1fnPMf7"
      },
      "outputs": [],
      "source": [
        "# Example 2: Complete Resume Request\n",
        "input_2 = \"\"\"\n",
        "I need a resume for a Senior Python Developer role.\n",
        "Requirements: 5+ years of Python, Django, FastAPI, AWS experience.\n",
        "My details:\n",
        "Name: Ajeet Kumar\n",
        "Contact: ajeet@example.com, 123-456-7890\n",
        "Skills: Python, Django, FastAPI, AWS, Docker\n",
        "Experience: 6 years at Tech Corp as Senior Dev. Built scalable APIs.\n",
        "Education: B.Tech in CS from XYZ University.\n",
        "\"\"\"\n",
        "print(\"\\n--- Test 2: Complete Input ---\")\n",
        "print(run_agent(input_2))"
      ],
      "id": "WRDoR1fnPMf7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcTd4bYDPMf7"
      },
      "outputs": [],
      "source": [
        "# Example 3: Cover Letter Request\n",
        "input_3 = \"\"\"\n",
        "Write a cover letter for a Frontend Engineer position at Google.\n",
        "Requirements: React, TypeScript, 3 years exp.\n",
        "My details: Ajeet, passionate about UI/UX, expert in React.\n",
        "\"\"\"\n",
        "print(\"\\n--- Test 3: Cover Letter ---\")\n",
        "print(run_agent(input_3))"
      ],
      "id": "dcTd4bYDPMf7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}